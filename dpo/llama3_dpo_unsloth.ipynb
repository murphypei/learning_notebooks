{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ unsloth å’Œ DPOTrainer å¾®è°ƒ Llama3 æ¨¡åž‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: xformers in /opt/conda/lib/python3.10/site-packages (0.0.28.post1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.10.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.4.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl) (0.8.11)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.14.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.12.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.8.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets trl peft bitsandbytes wandb accelerate transformers xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-vkdqcarg/unsloth_8973429625644cfbb9921b26b969a0d3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-vkdqcarg/unsloth_8973429625644cfbb9921b26b969a0d3\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 38663b01f5dd0e610b12475bd95b144303cff539\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unsloth-zoo (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Obtaining dependency information for unsloth-zoo from https://files.pythonhosted.org/packages/31/e9/1fee23655b1c0674a63b92ec960c04db12f01df27a1d45eac7de0b4f3651/unsloth_zoo-2024.10.1-py3-none-any.whl.metadata\n",
      "  Downloading unsloth_zoo-2024.10.1-py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1)\n",
      "Requirement already satisfied: tyro in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.11)\n",
      "Requirement already satisfied: transformers>=4.44.2 in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.0)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.25.1)\n",
      "Requirement already satisfied: hf-transfer in /opt/conda/lib/python3.10/site-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.8.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.1)\n",
      "Requirement already satisfied: triton>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.10/site-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.34.2)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 in /opt/conda/lib/python3.10/site-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.4.0->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Downloading unsloth_zoo-2024.10.1-py3-none-any.whl (39 kB)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.10.0-py3-none-any.whl size=161147 sha256=d141a1b0f1e439b42571d3323a427a5da3b0b9c0d57e6fdc32997c6dcb003d7c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ykluchat/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth, unsloth-zoo\n",
      "  Attempting uninstall: unsloth\n",
      "    Found existing installation: unsloth 2024.9.post4\n",
      "    Uninstalling unsloth-2024.9.post4:\n",
      "      Successfully uninstalled unsloth-2024.9.post4\n",
      "Successfully installed unsloth-2024.10.0 unsloth-zoo-2024.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NV_CUDA_COMPAT_PACKAGE cuda-compat-11-8\n",
      "NV_CUDA_NSIGHT_COMPUTE_VERSION 11.8.0-1\n",
      "CUDA_VERSION 11.8.0\n",
      "NVIDIA_REQUIRE_CUDA cuda>=11.8 brand=tesla,driver>=450,driver<451 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=510,driver<511 brand=unknown,driver>=510,driver<511 brand=nvidia,driver>=510,driver<511 brand=nvidiartx,driver>=510,driver<511 brand=geforce,driver>=510,driver<511 brand=geforcertx,driver>=510,driver<511 brand=quadro,driver>=510,driver<511 brand=quadrortx,driver>=510,driver<511 brand=titan,driver>=510,driver<511 brand=titanrtx,driver>=510,driver<511 brand=tesla,driver>=515,driver<516 brand=unknown,driver>=515,driver<516 brand=nvidia,driver>=515,driver<516 brand=nvidiartx,driver>=515,driver<516 brand=geforce,driver>=515,driver<516 brand=geforcertx,driver>=515,driver<516 brand=quadro,driver>=515,driver<516 brand=quadrortx,driver>=515,driver<516 brand=titan,driver>=515,driver<516 brand=titanrtx,driver>=515,driver<516\n",
      "NV_CUDA_LIB_VERSION 11.8.0-1\n",
      "NV_CUDA_CUDART_VERSION 11.8.89-1\n",
      "NV_CUDA_CUDART_DEV_VERSION 11.8.89-1\n",
      "NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE cuda-nsight-compute-11-8=11.8.0-1\n",
      "CUDA_VISIBLE_DEVICES 7\n",
      "\n",
      "True\n",
      "1\n",
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# unsloth ä¸æ”¯æŒå¤šGPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "for k, v in os.environ.items():\n",
    "    if \"cuda\" in k.lower():\n",
    "        print(k, v)\n",
    "\n",
    "print()\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import PatchDPOTrainer\n",
    "PatchDPOTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from unsloth import is_bfloat16_supported\n",
    "import gc\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer, TextStreamer\n",
    "\n",
    "max_prompt_length = 1024\n",
    "\n",
    "max_seq_length = 8192  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "base_model = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
    "output_model = f\"./output/{base_model}/dpo\"\n",
    "final_ckpt = f\"{output_model}/final_ckpt\"\n",
    "\n",
    "wandb_name = \"llama3-finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.0: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: Tesla V100-SXM2-32GB. Max memory: 31.739 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=base_model,  # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.0 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  # Supports any, but = 0 is optimized\n",
    "    bias=\"none\",  # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # We support rank stabilized LoRA\n",
    "    loftq_config=None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'prompt', 'chosen', 'chosen-rating', 'chosen-model', 'rejected', 'rejected-rating', 'rejected-model'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = \"argilla/ultrafeedback-binarized-preferences-cleaned\"\n",
    "\n",
    "dataset = load_dataset(train_dataset)['train']\n",
    "# dataset = dataset.select(range(100))\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classify the following sentence as the type of speech it is, considering the context of a physics problem. Additionally, provide an explanation of the mathematical concept behind the sentence, using LaTeX to represent the equation that represents the answer. Sentence: \"The answer is the force required to move a mass of 5kg with an acceleration of 1m/s^2.\"'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'In what ways can the programming language Go be utilized to conduct a comprehensive analysis and comparison of the nutritional and ingredient composition of freshly-cooked food and packaged food? Can you provide a sample code that effectively leverages Go to generate user-friendly insights and visualizations regarding the findings of the analysis?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Thank you for your question! I\\'m happy to help you explore the potential uses of the Go programming language for analyzing and comparing the nutritional and ingredient composition of freshly-cooked food and packaged food.\\nTo start with, Go is an excellent choice for this task due to its strong typing system, concise syntax, and built-in support for processing and data analysis capabilities. With Go, you can quickly and efficiently collect data from various sources, perform complex calculations, and visualize the results in a user-friendly manner.\\nHere are some potential ways you could use Go to conduct a comprehensive analysis and comparison of the nutritional and ingredient composition of freshly-cooked food and packaged food:\\n1. Data Collection: You can use Go to collect data from various sources such as nutrition labels, recipes, cooking methods, and so on. You can use libraries such as \"go-nut\" and \"go-cooking\" to easily read and parse nutrition labels and recipes, respectively.\\n2. Data Processing: Once you have collected the data, you can use Go to process and analyze it. For example, you can calculate the macronutrient and micronutrient composition of freshly-cooked food and packaged food, compare their nutritional values, and identify any patterns or trends. You can use libraries such as \"go-gmp\" and \"go-nut\" for this purpose.\\n3. Data Visualization: After processing the data, you can use Go to visualize the findings in a user-friendly manner. You can use libraries such as \"go-graphviz\" and \"go-golang-visualization\" to create detailed and informative visualizations that highlight the key differences and similarities between freshly-cooked food and packaged food.\\nHere is a sample code that demonstrates how you can use Go to perform a basic analysis and comparison of the nutritional and ingredient composition of freshly-cooked food and packaged food:\\n```\\n```\\n```\\n```\\n```\\nThis code reads the nutrition labels of two food items, calculates their macronutrient and micronutrient composition, and compares their values. You can modify the code to include additional food items, or to analyze different aspects of their nutritional content.\\nIn terms of visualization, you can use Go to create detailed and informative plots that represent the findings of your analysis. For example, you can create a bar chart to show the macronutrient composition of each food item, or a pie chart to illustrate the distribution of different micronutrients.\\nOverall, Go is an excellent programming language for conducting a comprehensive analysis and comparison of the nutritional and ingredient composition of freshly-cooked food and packaged food. Its strong typing system, concise syntax, and built-in support for data processing and visualization make it an ideal choice for this task.\\nI hope this helps! Let me know if you have any other questions.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['rejected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Classify the following sentence as the type of speech it is, considering the context of a physics problem. Additionally, provide an explanation of the mathematical concept behind the sentence, using LaTeX to represent the equation that represents the answer. Sentence: \"The answer is the force required to move a mass of 5kg with an acceleration of 1m/s^2.\"',\n",
       "  'role': 'user'},\n",
       " {'content': \"The given sentence can be classified as an informative or declarative statement as it conveys information about a physics problem, specifically the calculation of force.\\n\\nThe concept behind the sentence refers to Newton's second law of motion, which states that the force acting on an object is equal to the product of its mass and acceleration. Mathematically, it can be represented using the equation:\\n\\n$$ F = m \\\\times a$$\\n\\nWhere,\\n- $F$ represents the force\\n- $m$ represents the mass of the object (in this case, 5 kg)\\n- $a$ represents the acceleration (in this case, 1 m/sÂ²)\\n\\nUsing the given values, we can calculate the force as:\\n\\n$$ F = 5\\\\, kg \\\\times 1\\\\, m/s^2 $$\\n\\n$$ F = 5\\\\, N $$\\n\\nSo, the force required to move a mass of 5 kg with an acceleration of 1 m/sÂ² is 5 Newtons (N).\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['chosen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% if messages[0]['role'] == 'system' %}\\n    {% set offset = 1 %}\\n{% else %}\\n    {% set offset = 0 %}\\n{% endif %}\\n\\n{{ bos_token }}\\n{% for message in messages %}\\n    {% if (message['role'] == 'user') != (loop.index0 % 2 == offset) %}\\n        {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\\n    {% endif %}\\n\\n    {{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n' + message['content'] | trim + '<|eot_id|>' }}\\n{% endfor %}\\n\\n{% if add_generation_prompt %}\\n    {{ '<|start_header_id|>' + 'assistant' + '<|end_header_id|>\\\\n\\\\n' }}\\n{% endif %}\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = open('llama-3-instruct.jinja').read()\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% if messages[0]['role'] == 'system' %}{% set offset = 1 %}{% else %}{% set offset = 0 %}{% endif %}{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == offset) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n' + message['content'] | trim + '<|eot_id|>' }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>' + 'assistant' + '<|end_header_id|>\\\\n\\\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = chat_template.replace('    ', '').replace('\\n', '')\n",
    "tokenizer.chat_template = chat_template\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assistant_content(data):\n",
    "    for item in data:\n",
    "        if item[\"role\"] == \"assistant\":\n",
    "            return item[\"content\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_question_content(data):\n",
    "    for item in data:\n",
    "        if item[\"role\"] == \"user\":\n",
    "            return item[\"content\"]\n",
    "    return \"\"\n",
    "\n",
    "system_prompt = \"You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.\"\n",
    "\n",
    "def dataset_format(example):\n",
    "    # Format system\n",
    "    if \"system\" in example and len(example[\"system\"]) > 0:\n",
    "        message = {\"role\": \"system\", \"content\": example[\"system\"]}\n",
    "        system = tokenizer.apply_chat_template([message], tokenize=False)\n",
    "    else:\n",
    "        message = {\"role\": \"system\", \"content\": system_prompt}\n",
    "        system = tokenizer.apply_chat_template([message], tokenize=False)\n",
    "    # Format instruction\n",
    "    message = {\"role\": \"user\", \"content\": get_question_content(example[\"chosen\"])}\n",
    "    prompt = tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)\n",
    "    # Format chosen answer\n",
    "    chosen = get_assistant_content(example[\"chosen\"]) + \"<|eot_id|>\\n\"\n",
    "    # Format rejected answer\n",
    "    rejected = get_assistant_content(example[\"rejected\"]) + \"<|eot_id|>\\n\"\n",
    "    return {\n",
    "        \"prompt\": system + prompt,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.<|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nClassify the following sentence as the type of speech it is, considering the context of a physics problem. Additionally, provide an explanation of the mathematical concept behind the sentence, using LaTeX to represent the equation that represents the answer. Sentence: \"The answer is the force required to move a mass of 5kg with an acceleration of 1m/s^2.\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " 'chosen': \"The given sentence can be classified as an informative or declarative statement as it conveys information about a physics problem, specifically the calculation of force.\\n\\nThe concept behind the sentence refers to Newton's second law of motion, which states that the force acting on an object is equal to the product of its mass and acceleration. Mathematically, it can be represented using the equation:\\n\\n$$ F = m \\\\times a$$\\n\\nWhere,\\n- $F$ represents the force\\n- $m$ represents the mass of the object (in this case, 5 kg)\\n- $a$ represents the acceleration (in this case, 1 m/sÂ²)\\n\\nUsing the given values, we can calculate the force as:\\n\\n$$ F = 5\\\\, kg \\\\times 1\\\\, m/s^2 $$\\n\\n$$ F = 5\\\\, N $$\\n\\nSo, the force required to move a mass of 5 kg with an acceleration of 1 m/sÂ² is 5 Newtons (N).<|eot_id|>\\n\",\n",
       " 'rejected': 'The sentence is a statement. The formula for force is F = ma, where F is the force applied, m is the mass of the object, and a is the acceleration. Therefore, the force required to move a mass of 5 kg with an acceleration of 1 m/s^2 is F = (5 kg) (1 m/s^2) = (5 kg m/s^2)/kg = 5 N. LaTeX: F=ma. F = (5 kg) (1 m/s^2) = (5 kg m/s^2)/kg = 5 N.<|eot_id|>\\n'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_format(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581e40bd8cc143c18304a54fec296881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=96):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_columns = dataset.column_names\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "dataset = dataset.map(\n",
    "    dataset_format,\n",
    "    remove_columns=original_columns,\n",
    "    num_proc=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "os.environ[\"WANDB_PROJECT\"] = wandb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_config = DPOConfig(\n",
    "    output_dir=output_model,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    num_train_epochs=1,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    warmup_steps=10,\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    report_to=\"wandb\",\n",
    "    beta=0.1,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_length=max_seq_length,\n",
    "    force_use_ref_model=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2854eedbb30d452ca008886afc9b26bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.9.70, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    None,\n",
    "    args=dpo_config,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 100 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 12\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ws/code/github/notebooks/wandb/run-20241015_113732-bszeneun</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/murphypei/llama3-finetune/runs/bszeneun' target=\"_blank\">./output/unsloth/Llama-3.2-3B-Instruct-bnb-4bit/dpo</a></strong> to <a href='https://wandb.ai/murphypei/llama3-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/murphypei/llama3-finetune' target=\"_blank\">https://wandb.ai/murphypei/llama3-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/murphypei/llama3-finetune/runs/bszeneun' target=\"_blank\">https://wandb.ai/murphypei/llama3-finetune/runs/bszeneun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:11, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-346.599487</td>\n",
       "      <td>-439.619568</td>\n",
       "      <td>-0.831523</td>\n",
       "      <td>0.214761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-374.947754</td>\n",
       "      <td>-530.129639</td>\n",
       "      <td>-0.398564</td>\n",
       "      <td>-0.181835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.693700</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-330.874084</td>\n",
       "      <td>-433.769257</td>\n",
       "      <td>-0.486776</td>\n",
       "      <td>-0.211405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.003491</td>\n",
       "      <td>-304.160706</td>\n",
       "      <td>-361.233795</td>\n",
       "      <td>-0.690558</td>\n",
       "      <td>-0.302086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>-0.005834</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>-393.764587</td>\n",
       "      <td>-449.716248</td>\n",
       "      <td>-0.705344</td>\n",
       "      <td>-0.171326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.013360</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>-322.016052</td>\n",
       "      <td>-604.729370</td>\n",
       "      <td>-0.942304</td>\n",
       "      <td>-0.138371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>-0.001494</td>\n",
       "      <td>-0.003322</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-359.222412</td>\n",
       "      <td>-402.259766</td>\n",
       "      <td>-0.454612</td>\n",
       "      <td>-0.269678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>-0.008910</td>\n",
       "      <td>-0.015593</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>-332.230469</td>\n",
       "      <td>-456.787598</td>\n",
       "      <td>-0.832791</td>\n",
       "      <td>-0.227270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>-0.016832</td>\n",
       "      <td>-0.052506</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.035675</td>\n",
       "      <td>-322.846863</td>\n",
       "      <td>-413.016296</td>\n",
       "      <td>-0.432009</td>\n",
       "      <td>-0.311457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.677200</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>-0.035945</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.032899</td>\n",
       "      <td>-522.161987</td>\n",
       "      <td>-384.475769</td>\n",
       "      <td>-0.172401</td>\n",
       "      <td>-0.461164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>-473.935181</td>\n",
       "      <td>-380.669983</td>\n",
       "      <td>-0.200163</td>\n",
       "      <td>-0.345495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.651400</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.089780</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>-384.586334</td>\n",
       "      <td>-425.167969</td>\n",
       "      <td>-0.715851</td>\n",
       "      <td>-0.340007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=0.6849456280469894, metrics={'train_runtime': 82.561, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.145, 'total_flos': 0.0, 'train_loss': 0.6849456280469894, 'epoch': 0.96})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 157.05 out of 251.58 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 77.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(final_ckpt, tokenizer, save_method=\"merged_16bit\")\n",
    "# model.save_pretrained_merged(final_ckpt, tokenizer, save_method = \"merged_4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush memory\n",
    "# del dpo_trainer, model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.0: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: Tesla V100-SXM2-32GB. Max memory: 31.739 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df97a4d9c954f86b31e78a7304fc3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./output/unsloth/Llama-3.2-3B-Instruct-bnb-4bit/dpo/final_ckpt does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=final_ckpt,  # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
       "          18328,   6369,   6465,    430,   5825,  64694,  11503,     13, 128009,\n",
       "         128006,    882, 128007,    271,   3923,    527,  71503,    323,   3249,\n",
       "           1053,    358,   1005,   1124,    369,   5780,   6975,   9256,     30,\n",
       "         128009, 128006,  78191, 128007,    271]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format prompt\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant chatbot that provides concise answers.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are GPUs and why would I use them for machine learning tasks?\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\n",
    "    \"cuda\"\n",
    ")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant chatbot that provides concise answers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What are GPUs and why would I use them for machine learning tasks?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**What are GPUs?**\n",
      "\n",
      "Graphics Processing Units (GPUs) are specialized computer chips designed to perform massive parallel processing, making them extremely efficient for computationally intensive tasks.\n",
      "\n",
      "**Why use GPUs for machine learning?**\n",
      "\n",
      "GPUs are particularly well-suited for machine learning (ML) tasks because they:\n",
      "\n",
      "1. **Speed up computations**: GPUs can perform many calculations simultaneously, reducing the time required for tasks like matrix multiplication, convolution, and neural network computations.\n",
      "2. **Reduce memory bandwidth**: GPUs have high memory bandwidth, allowing for faster data transfer between the GPU and host system.\n",
      "3. **Increase parallelism**: GPUs can handle many tasks in parallel, making them ideal for tasks like image processing, natural language processing, and computer vision.\n",
      "\n",
      "**Common use cases for GPUs in machine learning:**\n",
      "\n",
      "1. **Deep learning**: GPUs are essential for training and deploying deep neural networks, such as those used in computer vision, natural language processing, and speech recognition.\n",
      "2. **Accelerated computing**: GPUs can speed up tasks like image processing, data compression, and scientific simulations.\n",
      "3. **High-performance computing**: GPUs can be used for tasks like data analytics, data mining, and data science.\n",
      "\n",
      "**Popular GPU frameworks for machine learning:**\n",
      "\n",
      "1. **TensorFlow**: An open-source ML framework that supports GPU acceleration.\n",
      "2. **PyTorch**: An open-source ML framework that supports GPU acceleration.\n",
      "3. **Caffe**: A deep learning framework that supports GPU acceleration.\n",
      "\n",
      "In summary, GPUs are designed to speed up computationally intensive tasks, making them an essential component for many machine learning applications.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(input_ids=inputs, streamer=text_streamer, max_new_tokens=1024, use_cache=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
